{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pdb\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "from matplotlib import pyplot as plt\n",
    "from cycler import cycler\n",
    "\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "# hueristic way to navigate one folder above the notebooks directory\n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir('..')\n",
    "    \n",
    "! pwd\n",
    "print(1)    \n",
    "#from train import Config\n",
    "print(2)\n",
    "#from vtab import VTAB_DATASET_NAMES, ADDITIONAL_DATASET_NAMES, DATASET_NAMES, SPECIALIZED_DATASET_NAMES, SPECIALIZED_DATASET_NAMES\n",
    "print(3)\n",
    "\n",
    "# host = !echo $HOST\n",
    "# if 'c-0' in host[0]:\n",
    "#     os.chdir(os.path.expanduser('~/expriment-starter'))\n",
    "# else:\n",
    "#     os.chdir('/Users/ycarmon/Drive/Research/DoG/vision_experiments')\n",
    "    \n",
    "# from src import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_groupby(df, labels):\n",
    "    if type(labels) == str:\n",
    "        df.groupby(labels, dropna=False)\n",
    "\n",
    "    if len(labels) == 0:\n",
    "        return [(\"\", df)]\n",
    "    \n",
    "    if len(labels) == 1:\n",
    "        labels = labels[0]\n",
    "    \n",
    "    return df.groupby(labels, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_experiments(experiment_names, index_field='epoch', read_train=False, folder='results'):\n",
    "    experiment_names = [os.path.join(folder, ename) for ename in experiment_names]\n",
    "    paths_to_plot = [os.path.join(ename, fname) for ename in experiment_names \n",
    "                     for fname in os.listdir(ename) if not (fname.endswith('.yaml') or fname.endswith('.sh') or 'logs' in fname)] \n",
    "    short_names = paths_to_plot #[n.replace(experiment_name + '_', '') for n in folders_to_plot]\n",
    "    # short_names\n",
    "\n",
    "    _RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "\n",
    "    train_dfs = {}\n",
    "    eval_dfs = {}\n",
    "    configs = {}\n",
    "    for folder_name, short_name in tqdm.tqdm(list(zip(paths_to_plot, short_names))):\n",
    "        is_done = os.path.exists(os.path.join(folder_name, 'done'))\n",
    "\n",
    "        eval_path = os.path.join(folder_name, 'stats_eval.csv')\n",
    "        eval_path_tmp = os.path.join(folder_name, 'stats_eval_tmp.csv')\n",
    "        with open(eval_path, 'r') as f:\n",
    "            csv_text = f.read()\n",
    "        if csv_text[0] != ',':\n",
    "            print(short_name)\n",
    "            continue\n",
    "        csv_text = csv_text.replace(',[',',\"[')\n",
    "        csv_text = csv_text.replace('],',']\",')\n",
    "        csv_text = csv_text.replace('[ ','[')\n",
    "        csv_text = csv_text.replace(' ]',']')\n",
    "        csv_text = csv_text.replace('. ','.0')\n",
    "        csv_text = ' '.join(csv_text.split(sep=' '))\n",
    "        with open(eval_path_tmp, 'w') as f:\n",
    "            f.write(csv_text)\n",
    "        try:\n",
    "            df = pd.read_csv(eval_path_tmp)#(StringIO(csv_text))#(eval_path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        with open(os.path.join(folder_name, 'args.yaml'), 'r') as f:\n",
    "            configs[short_name] = yaml.safe_load(f) # asdict(Config(**yaml.safe_load(f)))\n",
    "    #     df['name'] = short_name\n",
    "        configs[short_name]['is_done'] = is_done\n",
    "        if not 'loss' in configs[short_name]:\n",
    "            configs[short_name]['loss'] = 'none'\n",
    "\n",
    "        \n",
    "        df = df.rename(columns={'Unnamed: 0': 'epoch'}).rename(columns=lambda x: x.replace('eval/', 'test/'))\n",
    "        #print(short_name, len(df.columns), df.columns)\n",
    "        df['epoch'] += 1\n",
    "\n",
    "        assert(index_field != 'step')\n",
    "        #df['step'] = df['train/seen_examples'] / configs[short_name]['batch_size']\n",
    "        \n",
    "        if read_train:\n",
    "            assert(False)\n",
    "            train_df = pd.read_csv(os.path.join(folder_name, 'stats_train.csv'))\n",
    "            train_df = train_df.rename(columns={'Unnamed: 0': 'step'})\n",
    "            train_df['step'] = (train_df['step'] + 1) / configs[short_name]['grad_accum_steps']\n",
    "            train_df['epoch'] = ((train_df['seen_examples'] - 1) / df.iloc[0]['train/seen_examples']).astype(int)\n",
    "            train_df = train_df[ train_df['seen_examples'] % configs[short_name]['batch_size'] == 0 ]\n",
    "            train_df = train_df.set_index(index_field)\n",
    "            train_dfs[short_name] = train_df\n",
    "        \n",
    "        if os.path.exists(os.path.join(folder_name, 'stats_regret.csv')):\n",
    "            regret_df = pd.read_csv(os.path.join(folder_name, 'stats_regret.csv')).set_index('epoch')\n",
    "            regret_df['regret_ratio'] = regret_df.regret / regret_df.loss_diff\n",
    "            regret_df = pd.concat([split_df.rename(columns=lambda x: split + '/' + x) for split, split_df in modified_groupby(regret_df,'split')], axis=1)\n",
    "            df = pd.concat([df.set_index('epoch'), regret_df], axis=1).reset_index()\n",
    "        \n",
    "        df = df.set_index(index_field)\n",
    "        eval_dfs[short_name] = df\n",
    "        # eval_dfs[short_name] = eval_dfs[short_name].rename(columns=lambda n: n.replace('accuracy_av', 'accuracy/average'))\n",
    "    #     train_dfs[short_name] = modified_groupby(pd.read_csv(os.path.join(experiment_name, folder_name, 'stats_train.csv')),'epoch').mean()\n",
    "        \n",
    "\n",
    "    print('Successfully read %d out of %d folders' % (len(eval_dfs) ,len(paths_to_plot)))\n",
    "\n",
    "    keys = set([c for df in eval_dfs.values() for c in df.columns])  # remove \n",
    "\n",
    "    # turn every run into a \"row\" in a dataframe that also contains the entire config\n",
    "    big_df = pd.DataFrame(configs).T.rename_axis('name').sort_index()\n",
    "    for key in keys:\n",
    "        big_df[key] = [eval_dfs[name][key] if key in eval_dfs[name].columns else np.array([]) for name in big_df.index]\n",
    "        \n",
    "    if read_train:\n",
    "        keys = set([c for df in train_dfs.values() for c in df.columns])\n",
    "        for key in keys:\n",
    "            big_df['training/' + key] = [train_dfs[name][key] if key in train_dfs[name].columns else np.array([]) for name in big_df.index]\n",
    "\n",
    "#     # throw away stuff that didn't finish running\n",
    "# #     valid_mask = big_df.epochs == big_df['test/robust_loss'].apply(len)\n",
    "#     valid_mask = big_df['eval/loss'].apply(len) > 0 # == big_df['eval_num']\n",
    "#     big_df = big_df[valid_mask]\n",
    "#     config_df = pd.DataFrame(configs).T.rename_axis('name').sort_index()[valid_mask]\n",
    "# #     config_df['ada_eps'].fillna(1e-8, inplace=True)\n",
    "\n",
    "    print('%d results left after filtering' % (len(big_df),))\n",
    "    \n",
    "#     big_df.loc[big_df['training_examples'] < 0, 'training_examples'] = np.inf\n",
    "\n",
    "    return big_df\n",
    "\n",
    "@dataclass\n",
    "class Interval:\n",
    "    start: float = -np.inf\n",
    "    end: float = np.inf\n",
    "\n",
    "def filt(df, **kwargs):\n",
    "    filt_df = df.copy()\n",
    "    for k, v in kwargs.items():\n",
    "        if callable(v):\n",
    "            filt_df = filt_df.loc[filt_df[k].apply(v)]\n",
    "        elif isinstance(v, str):\n",
    "            if v.startswith('~'):\n",
    "                filt_df = filt_df.loc[~filt_df[k].str.contains(v[1:])]\n",
    "            else:\n",
    "                filt_df = filt_df.loc[filt_df[k].str.contains(v)]\n",
    "        elif isinstance(v, tuple):\n",
    "            for vv in v:\n",
    "                filt_df = filt(filt_df, **{k: vv})\n",
    "        elif isinstance(v, list):\n",
    "            filt_df = pd.concat([filt(filt_df, **{k: vv}) for vv in v], axis=0)\n",
    "        elif isinstance(v, float) or isinstance(v, int) or isinstance(v, bool):\n",
    "            filt_df = filt_df.loc[filt_df[k]==v]\n",
    "        elif isinstance(v, Interval):\n",
    "            filt_df = filt_df[(v.start <= filt_df[k]) & (filt_df[k] <= v.end)]\n",
    "        else:\n",
    "          raise ValueError(f'Don''t know how to handle filter type {type(v)}')\n",
    "    return filt_df\n",
    "\n",
    "def pick_best(df, index_columns, target_column, k_best=1, horizon=np.inf): \n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'loss' in target_column:\n",
    "        op = lambda x: -x.truncate(after=horizon).min()\n",
    "    else:\n",
    "        op = lambda x: x.truncate(after=horizon).max()\n",
    "\n",
    "    df['target'] = df[target_column].apply(op)\n",
    "\n",
    "    if len(index_columns)  > 0:\n",
    "        df = df.reset_index().set_index(index_columns).sort_index()\n",
    "        best_rows = pd.DataFrame()\n",
    "        for i in df.index.unique():\n",
    "            best_rows = best_rows.append(df.loc[[i]].nlargest(k_best, 'target'))\n",
    "    else:\n",
    "        best_rows = df.nlargest(k_best, 'target')\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    return best_rows.reset_index().set_index('name')\n",
    "\n",
    "def nanfloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def nice_string(s):\n",
    "    return s.replace('_', ' ').capitalize()\n",
    "\n",
    "def short_string(s, strlen=12):\n",
    "    return '_'.join([ss[:strlen] for ss in s.split('_')])\n",
    "\n",
    "def config_str(ks, vs, key_len=12, sep=', '):\n",
    "    if not isinstance(vs, tuple) or isinstance(vs, list):\n",
    "        vs = [vs]\n",
    "    return sep.join([f'{short_string(k, strlen=key_len)} = {v}' for k, v in zip(ks, vs)])\n",
    "\n",
    "MARKERS = ['o', 'v', 'p', 'X', '<', 's', '^','P', '*', '>', 'd']\n",
    "LINESTYLES = ['-', '--', ':', '-.']\n",
    "COLORS = [c for c in matplotlib.colors.TABLEAU_COLORS]#[:-2]\n",
    "\n",
    "def get_marker(i):\n",
    "    return MARKERS[i % len(MARKERS)]\n",
    "\n",
    "def get_color(i, clist=None):\n",
    "    if clist is None:\n",
    "        clist = COLORS\n",
    "    return clist[i % len(clist)]\n",
    "\n",
    "def get_linestyle(i):\n",
    "    return LINESTYLES[i % len(LINESTYLES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = np.sort(os.listdir('results'))\n",
    "folders_quotes = [f\"'{f}'\" for f in folders]\n",
    "print(f'[{\", \".join(folders_quotes)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nanmin(arr):\n",
    "    if len(arr) == 0 or np.all(np.isnan(arr)):\n",
    "        return np.nan\n",
    "    return np.nanmin(arr)\n",
    "\n",
    "def clean_nanmax(arr):\n",
    "    if len(arr) == 0 or np.all(np.isnan(arr)):\n",
    "        return np.nan\n",
    "    return np.nanmax(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dist_to_rbar(dist):\n",
    "    if isinstance(dist, float):\n",
    "        return dist\n",
    "    elif isinstance(dist, str):\n",
    "        dist_arr = np.fromstring(dist[1:-1], dtype=np.float64, sep=' ')\n",
    "        return dist_arr#np.linalg.norm(dist_arr)\n",
    "    raise  Exception('dist of unknown type ' + str(type(dist)))\n",
    "\n",
    "def generate_dog_data_partial(df):\n",
    "    accele_df = df.query('optim_alg != \"dog\" and optim_alg != \"dog_public\"').copy()\n",
    "    accele_df.loc[:,'train/effective_lr'] = accele_df.loc[:,'train/alpha'] * accele_df.loc[:,'train/eta']\n",
    "\n",
    "    return accele_df\n",
    "\n",
    "def generate_dog_data(df, with_effective_lr = True, dog=True, adog=True):\n",
    "    dog_df = df.query('optim_alg == \"dog\" or optim_alg == \"dog_public\"').copy()\n",
    "    accele_df = df.query('optim_alg != \"dog\" and optim_alg != \"dog_public\"').copy()\n",
    "\n",
    "    if dog:\n",
    "        dog_df.loc[:,'train/rbar'] = dog_df.loc[:,'train/dog/init_dist'].map( lambda x: x.map( lambda y: init_dist_to_rbar(y)))\n",
    "        dog_df.loc[:,'train/alpha'] = dog_df.loc[:,'train/dog/init_dist'].map( lambda x: x.map( lambda y: 1.))\n",
    "        dog_df.loc[:,'train/eta'] = dog_df.loc[:,'train/dog/eta']\n",
    "\n",
    "    if adog:\n",
    "        accele_df.loc[:,'train/rbar'] = accele_df.loc[:,'train/rbar'].map( lambda x: x.map( lambda y: init_dist_to_rbar(y)))\n",
    "\n",
    "    if dog and adog:\n",
    "        new_df = pd.concat([dog_df, accele_df])\n",
    "    elif dog:\n",
    "        new_df = dog_df\n",
    "    else:\n",
    "        new_df = accele_df\n",
    "\n",
    "    if with_effective_lr:\n",
    "        new_df.loc[:,'train/effective_lr'] = new_df.loc[:,'train/alpha'] * new_df.loc[:,'train/eta']\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def get_best_losses(*dfs):\n",
    "    best_losses = {}\n",
    "\n",
    "    for df in dfs:\n",
    "        for loss in df['loss'].unique():\n",
    "            best_loss = clean_nanmin( df.query(f'loss == \"{loss}\"').filter(regex='.*/loss').applymap( clean_nanmin ).values )\n",
    "            best_losses[loss] = clean_nanmin( [best_loss, best_losses.get(loss, np.inf)] )\n",
    "\n",
    "    return best_losses\n",
    "\n",
    "def generate_subopt_helper(df, best_loss):\n",
    "    best_loss = clean_nanmin( df.filter(regex='.*/loss').applymap( clean_nanmin ).values )\n",
    "    for key in df.filter(regex='.*/loss').columns:\n",
    "        subopt_key = key[:-4] + \"empirical_subopt\"\n",
    "        df.loc[:,subopt_key] = df.loc[:,key] - best_loss\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_subopt(df, best_losses: dict = None):\n",
    "\n",
    "    if best_losses is None:\n",
    "        best_losses = get_best_losses(df)\n",
    "\n",
    "    new_dfs = []\n",
    "    for loss in df['loss'].unique():\n",
    "        new_df = df.query(f'loss == \"{loss}\"').copy()\n",
    "        new_df = generate_subopt_helper(new_df, best_losses[loss])\n",
    "        new_dfs.append(new_df)\n",
    "\n",
    "\n",
    "    new_df = pd.concat(new_dfs)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_find_best(df, field='train/empirical_subopt', method = \"best\"):\n",
    "    row_fields = ['model', 'dataset', 'batch_size', 'loss', 'momentum', 'activation']\n",
    "    legend_fields = ['base_lr']\n",
    "\n",
    "    best_func = clean_nanmin\n",
    "    best_value_init = np.inf\n",
    "    if 'accuracy' in field:\n",
    "        best_func = clean_nanmax\n",
    "        best_value_init = -np.inf\n",
    "\n",
    "    arr_best = lambda arr: arr.iloc[-1]\n",
    "    if method == \"best\":\n",
    "        arr_best = lambda arr: best_func(arr)\n",
    "\n",
    "    rows = []\n",
    "    count=0\n",
    "    #df['is_best'] = df['dog_granularity'].map( lambda y: False)\n",
    "    for i_row, (row_vals, row_df) in enumerate(modified_groupby(df, row_fields)):\n",
    "\n",
    "        best_value = best_value_init\n",
    "        # Finding the best value\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_df,legend_fields)):\n",
    "            assert(len(entry_df[field]) == 1)\n",
    "            current_best_value = arr_best(entry_df[field][0])\n",
    "            \n",
    "            if not np.isnan(current_best_value):\n",
    "                if best_value is None:\n",
    "                    best_value = current_best_value\n",
    "                best_value = best_func([best_value, current_best_value])\n",
    "\n",
    "        # Add correct entry\n",
    "        found = False\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_df,legend_fields)):\n",
    "            last_epoch = len(entry_df[field][0])\n",
    "            current_best_value = arr_best(entry_df[field][0])\n",
    "            if (best_value == current_best_value):\n",
    "                rows.append(entry_df)\n",
    "\n",
    "    return pd.concat(rows)#.query('is_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_series(x, limit):\n",
    "    if limit is None or limit <= 0 or isinstance(x, (np.floating,float)):\n",
    "        return x\n",
    "    return x[:limit] if isinstance(x, np.ndarray) else x.truncate(after=limit)\n",
    "\n",
    "def create_last_and_best(df, limit=None):\n",
    "    for keyword in ['loss', 'empirical_subopt', 'accuracy']:\n",
    "        for key in df.filter(regex='.*/'+keyword).columns:\n",
    "\n",
    "            is_float_or_empty = lambda x: isinstance(x, (np.floating,float)) or len(x) == 0\n",
    "\n",
    "            # Last\n",
    "            key_last = key[:-len(keyword)] + 'last_' + keyword\n",
    "            df.loc[:,key_last] = df.loc[:,key].map( lambda x: np.nan if is_float_or_empty(limit_series(x, limit)) else limit_series(x, limit).iloc[-1] )\n",
    "\n",
    "            # Best\n",
    "            best_func = clean_nanmin\n",
    "            if keyword == 'accuracy':\n",
    "                best_func = clean_nanmax\n",
    "            key_best = key[:-len(keyword)] + 'best_' + keyword\n",
    "            df.loc[:,key_best] = df.loc[:,key].map( lambda x: np.nan if is_float_or_empty(limit_series(x, limit)) else best_func(limit_series(x, limit)) )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_av(df, av='constant_8'):\n",
    "    df = df\n",
    "\n",
    "    for col in df.filter(regex='.*/'+ av + '/.*').columns:\n",
    "        av_col = col.replace('/'+ av + '/', '/av/')\n",
    "        df[av_col] = df[col]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table  Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_value(df, fields, y_field, use_max=True):\n",
    "    best_func = clean_nanmax if use_max else clean_nanmin\n",
    "    worst_func = clean_nanmin if use_max else clean_nanmax\n",
    "\n",
    "    best_dict = {}\n",
    "    initial_dict = {}\n",
    "    for i_row, (row_vals, row_df) in enumerate(modified_groupby(df,fields)):\n",
    "        key =str(row_vals)\n",
    "        best_dict[key] = best_func( row_df.loc[:,y_field].apply( best_func ).values )\n",
    "        initial_dict[key] = worst_func( row_df.loc[:,y_field].apply( lambda x: x.iloc[0] ).values )\n",
    "\n",
    "    return best_dict, initial_dict\n",
    "\n",
    "def get_number_of_steps_until(df, fields, col_fields, y_field, best_dict, until, use_max=True, initial_dict=None):\n",
    "    \n",
    "    dfs_arr = []\n",
    "    dfs_dict = {}\n",
    "    key_to_vals = {}\n",
    "    for i_row, (row_vals, row_df) in enumerate(modified_groupby(df,fields)):\n",
    "        key = str(row_vals)\n",
    "        key_to_vals[key] = row_vals\n",
    "        if initial_dict is None:\n",
    "            until_value = best_dict[key] * until\n",
    "        else:\n",
    "            assert use_max\n",
    "            until_value = (best_dict[key] - initial_dict[key]) * until + initial_dict[key]\n",
    "        df_copy = row_df.copy()\n",
    "\n",
    "        from_where = df_copy.loc[:,y_field].apply( lambda x: x.apply( lambda y: (-np.inf if use_max else np.inf) if np.isnan(y) else y ) )\n",
    "        from_where = from_where.apply( lambda x: x>= until_value if use_max else x<= until_value )\n",
    "        from_where = from_where.apply( lambda x: x.idxmax() if x.max() else np.inf, axis='columns' )\n",
    "        df_copy.loc[:,'steps_until'] = from_where\n",
    "        dfs_arr.append(df_copy)\n",
    "\n",
    "        tmp_dict = {}\n",
    "        for n in df_copy.index:\n",
    "            tmp_dict[n] = str(df_copy.loc[n,col_fields].values)\n",
    "\n",
    "        dfs_dict[key] = from_where.rename( tmp_dict )\n",
    "    \n",
    "    new_table = pd.DataFrame.from_dict(dfs_dict, 'index')\n",
    "    for key in key_to_vals:\n",
    "        new_table.loc[key, fields] = key_to_vals[key]\n",
    "        #for feild, val in zip(fields, key_to_vals[key]):\n",
    "        #    new_table.loc[key, feild] = val\n",
    "\n",
    "    new_table = new_table.set_index(fields)\n",
    "\n",
    "    return new_table # pd.concat( dfs_arr ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_accuracy_val(sr, limit=None):\n",
    "    last_is_better = sr['val/last/accuracy'] > sr['val/av/accuracy']\n",
    "    best_val_acc = sr['val/last/accuracy'].where(last_is_better, sr['val/av/accuracy'])\n",
    "    best_test_acc = sr['test/last/accuracy'].where(last_is_better, sr['test/av/accuracy'])\n",
    "    if limit:\n",
    "        best_val_acc[:limit]\n",
    "    idx = best_val_acc.idxmax()\n",
    "\n",
    "    return best_test_acc[idx]\n",
    "\n",
    "def get_best_accuracy(sr, limit=None):\n",
    "    last_is_better = sr['test/last/accuracy'] > sr['test/av/accuracy']\n",
    "    best_test_acc = sr['test/last/accuracy'].where(last_is_better, sr['test/av/accuracy'])\n",
    "\n",
    "    if limit:\n",
    "        return best_test_acc[:limit].max()\n",
    "    return best_test_acc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_loss_val(sr, limit=None):\n",
    "    last_is_better = sr['val/last/loss'] > sr['val/av/loss']\n",
    "    best_val_acc = sr['val/last/loss'].where(last_is_better, sr['val/av/loss'])\n",
    "    best_test_acc = sr['test/last/loss'].where(last_is_better, sr['test/av/loss'])\n",
    "    if limit:\n",
    "        best_val_acc[:limit]\n",
    "    idx = best_val_acc.idxmin()\n",
    "\n",
    "    return best_test_acc[idx]\n",
    "\n",
    "def get_best_test_loss(sr, limit=None):\n",
    "    last_is_better = sr['test/last/loss'] > sr['test/av/loss']\n",
    "    best_test_acc = sr['test/last/loss'].where(last_is_better, sr['test/av/loss'])\n",
    "\n",
    "    if limit:\n",
    "        return best_test_acc[:limit].min()\n",
    "    return best_test_acc.min()\n",
    "\n",
    "\n",
    "def get_best_train_loss(sr, limit=None):\n",
    "    best_test_acc = sr['train/loss']\n",
    "\n",
    "    if limit:\n",
    "        return best_test_acc[:limit].min()\n",
    "    return best_test_acc.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loss_tables(df, rows='optim_alg', val=False, limit=None):\n",
    "    df = df.copy()\n",
    "    if val:\n",
    "        df['test/best/loss'] = df.apply(get_best_loss_val, args=(limit,), axis=1)\n",
    "    else:\n",
    "        df['test/best/loss'] = df.apply(get_best_test_loss, args=(limit,), axis=1)\n",
    "\n",
    "    models_names = []\n",
    "    for i_row, (row_vals, row_df) in enumerate(modified_groupby(df,['model'])):\n",
    "        models_names.append(row_vals)\n",
    "\n",
    "    tables = {}\n",
    "    for model_name in models_names:\n",
    "        model_df = df.query(f'model == \"{model_name}\"')\n",
    "\n",
    "        new_df = {}\n",
    "        for i_row, (row_vals, row_df) in enumerate(modified_groupby(model_df,rows)):\n",
    "            new_df[row_vals] = row_df['test/best/loss'].copy()\n",
    "            new_df[row_vals] = new_df[row_vals].rename(row_df['wd'])\n",
    "        tables[model_name] = pd.DataFrame.from_dict(new_df, 'index')\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loss_tables(df, rows='optim_alg', limit=None):\n",
    "    df = df.copy()\n",
    "    df['train/best/loss'] = df.apply(get_best_train_loss, args=(limit,), axis=1)\n",
    "\n",
    "    models_names = []\n",
    "    for i_row, (row_vals, row_df) in enumerate(modified_groupby(df,['model'])):\n",
    "        models_names.append(row_vals)\n",
    "\n",
    "    tables = {}\n",
    "    for model_name in models_names:\n",
    "        model_df = df.query(f'model == \"{model_name}\"')\n",
    "\n",
    "        new_df = {}\n",
    "        for i_row, (row_vals, row_df) in enumerate(modified_groupby(model_df,rows)):\n",
    "            new_df[row_vals] = row_df['train/best/loss'].copy()\n",
    "            new_df[row_vals] = new_df[row_vals].rename(row_df['wd'])\n",
    "        tables[model_name] = pd.DataFrame.from_dict(new_df, 'index')\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniXGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {'unixgrad': '+', 'accele_dog': '*', 'uni_dog': 's', 'dog_public': 'o', 'accelegrad': 'p'} \n",
    "colors = {'unixgrad': 'blue', 'accele_dog': 'orange', 'uni_dog': 'purple', 'dog_public': 'red', 'accelegrad': 'tab:purple'}\n",
    "colors_bounded = {'unixgrad': {\"True\": 'blue', \"False\": 'cyan'}, 'accelegrad': {\"True\": 'tab:purple', \"False\": 'tab:pink'}}\n",
    "nice_names = {'unixgrad': 'UniXGrad', 'accele_dog': 'A-DoG', 'uni_dog': 'U-DoG', 'dog_public': 'DoG', 'accelegrad': 'AcceleGrad'}\n",
    "names_order = ['accele_dog', 'uni_dog', 'dog_public', 'unixgrad', 'accelegrad']\n",
    "marker_size=7\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cmap = plt.cm.viridis\n",
    "def transform(val):\n",
    "    return -np.log10(1 - val)\n",
    "norm = mcolors.Normalize(vmin=transform(0), vmax=transform(0.9999))\n",
    "\n",
    "def make_sensitivity_plots(big_df_filt, epoch_selection = 'last', max_epoch_vals = [100, 400, 1000, 4000, 10000, 20000], \n",
    "                           rowsplit_keys = ['batch_size'], x_axis = 'diameter', y_axis = 'test/constant_8/accuracy', baseline_alg_mask = f'optim_alg in (\"unixgrad\", \"accelegrad\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg', 'bounded'], auto_y_lim_range = 0.05, y_lim = [0.8, 0.95],\n",
    "                           proposed_alg_mask = f'optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], fig=None, axes=None, colorbar=False):\n",
    "    pretty_mode = False\n",
    "    x_axis_categorical = False\n",
    "  \n",
    "    nrows = 1\n",
    "    ncols = len(max_epoch_vals)\n",
    "    assert not ((fig is None) ^ (axes is None))\n",
    "    create_legend = fig is None\n",
    "    \n",
    "    for rowsplit_vals, row_df in big_df_filt.groupby(rowsplit_keys):\n",
    "        hlines = []\n",
    "        print(rowsplit_vals, fig is None)\n",
    "\n",
    "        baseline_alg_df = row_df.query(baseline_alg_mask)\n",
    "        proposed_alg_df = row_df.query(proposed_alg_mask)\n",
    "        \n",
    "        if len(baseline_alg_df) == 0:\n",
    "            continue\n",
    "    \n",
    "        base_size = (7, 7) if not pretty_mode else (4, 4)\n",
    "        if fig is None:\n",
    "            print(\"??\")\n",
    "            fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(base_size[0] * ncols, base_size[1] * nrows), facecolor='w', sharey='row')\n",
    "        if nrows * ncols == 1:\n",
    "            axes = np.array(axes)\n",
    "        axes = axes.reshape(nrows, ncols)\n",
    "    \n",
    "        for j, max_epoch in enumerate(max_epoch_vals):\n",
    "            plt.sca(axes[0, j])\n",
    "            axes[0, j].clear()\n",
    "            \n",
    "            if len(baseline_alg_df[y_axis].iloc[0].truncate(after=max_epoch)) == 0:\n",
    "                continue\n",
    "                \n",
    "            baselines_to_plot = {}\n",
    "            \n",
    "            for i, (baseline_split_vals, baseline_split_df) in enumerate(baseline_alg_df.groupby(baseline_alg_split_keys, dropna=False)):\n",
    "                if epoch_selection == 'best':\n",
    "                    baseline_split_df['selected_y'] = baseline_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).max())\n",
    "                elif epoch_selection == 'last':\n",
    "                    baseline_split_df['selected_y'] = baseline_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).iloc[-1])\n",
    "                else:\n",
    "                    raise ValueError('?')\n",
    "                to_plot = baseline_split_df.groupby(x_axis, dropna=False)['selected_y'].max()\n",
    "                if x_axis_categorical:\n",
    "                    # to_plot.index = to_plot.index.fillna('none')\n",
    "                    to_plot.index = pd.Categorical(to_plot.index.values) #, categories=sorted(baseline_alg_df[x_axis].unique()))\n",
    "                # pdb.set_trace()\n",
    "            \n",
    "                baselines_to_plot[config_str(baseline_alg_split_keys, baseline_split_vals)] = to_plot\n",
    "                \n",
    "            baselines_to_plot = pd.DataFrame(baselines_to_plot)\n",
    "            baselines_to_plot.index = baselines_to_plot.index.fillna('none')\n",
    "            # styles = [dict(color=get_color(i), marker=get_marker(i)) for i in range(len(baselines_to_plot))]\n",
    "            # styles = [get_color(i) for i in range(len(baselines_to_plot))]\n",
    "            h = baselines_to_plot.plot(ax=plt.gca(), legend=False, ms=marker_size)\n",
    "            for i, ln in enumerate(h.lines):\n",
    "                ln.set_marker(get_marker(i))\n",
    "                # ln.set_color(get_color(i))\n",
    "                #momentum = float(baselines_to_plot.columns[i].split('momentum = ')[-1])\n",
    "                # pdb.set_trace()\n",
    "                #ln.set_color(get_momentum_color(momentum))\n",
    "                opt_alg = baselines_to_plot.columns[i].split(', ')[0].split('optim_alg = ')[-1]\n",
    "                bounded = baselines_to_plot.columns[i].split(', ')[1].split('bounded = ')[-1]\n",
    "                ln.set_color(colors_bounded[opt_alg][bounded])\n",
    "    \n",
    "            for ii, (proposed_split_vals, proposed_split_df) in enumerate(proposed_alg_df.groupby(proposed_alg_split_keys, dropna=False)):\n",
    "                if epoch_selection == 'best':\n",
    "                    proposed_split_df['selected_y'] = proposed_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).max())\n",
    "                elif epoch_selection == 'last':\n",
    "                    proposed_split_df['selected_y'] = proposed_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).iloc[-1])\n",
    "                else:\n",
    "                    raise ValueError('?')\n",
    "                to_plot = proposed_split_df['selected_y'].max()\n",
    "\n",
    "                # pdb.set_trace()\n",
    "                if len(proposed_split_vals) > 1 or proposed_split_vals[0] not in colors:\n",
    "                    color = colors.get(baseline_split_vals, get_color(-1-ii))\n",
    "                    plt.axhline(to_plot, color=color, ls='--', lw=2, label=f'{config_str(proposed_alg_split_keys, proposed_split_vals)}')\n",
    "                else:\n",
    "                    color = colors[proposed_split_vals[0]]\n",
    "                    marker = markers[proposed_split_vals[0]]\n",
    "                    hlines.append((color, marker, to_plot))\n",
    "                    plt.axhline(to_plot, color=color, lw=2, label=f'{config_str(proposed_alg_split_keys, proposed_split_vals)}')\n",
    "\n",
    "    \n",
    "            plt.title(f'Max {baseline_alg_df[y_axis].iloc[0].index.name} = {max_epoch}')\n",
    "            if not x_axis_categorical:\n",
    "                plt.xscale('log')\n",
    "            if y_lim == 'auto':\n",
    "                # y_max = min(1.0, pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.max()).max() + auto_y_lim_range)\n",
    "                # y_min = min(0.0, pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.min()).min() - auto_y_lim_range)\n",
    "                y_max = min(1.0, np.nanpercentile(pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.max()), 95) + auto_y_lim_range)\n",
    "                y_min = max(0.0, np.nanpercentile(pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.min()), 5) - auto_y_lim_range)\n",
    "                #plt.ylim(y_min, y_max)\n",
    "            else:    \n",
    "                plt.ylim(y_lim)\n",
    "            if 'loss' in y_axis or 'subopt' in y_axis or 'rbar' in y_axis:\n",
    "                plt.yscale('log')\n",
    "            plt.ylabel(y_axis)\n",
    "            plt.xlabel(x_axis)\n",
    "    \n",
    "            plt.grid(True, which='major', axis='y')\n",
    "            if not x_axis_categorical:\n",
    "                plt.grid(True, which='major', axis='x')\n",
    "            plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "    \n",
    "    \n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    \n",
    "        if create_legend:\n",
    "            fig.legend(\n",
    "                    prop={\"size\": 14},\n",
    "            #         columnspacing=0.0,\n",
    "                    ncol=5,\n",
    "                    handles=handles,\n",
    "                    labels=labels,\n",
    "                    loc='upper center',\n",
    "                    bbox_to_anchor=[0.5, -0.05],\n",
    "                    frameon=True,\n",
    "                    markerscale=1.0,\n",
    "                )\n",
    "            dataset_name = big_df_filt.iloc[0].dataset.replace('/', '+')\n",
    "            model_name = big_df_filt.iloc[0].model.replace('/', '+')\n",
    "            \n",
    "            fig.suptitle(f'{dataset_name} {config_str(rowsplit_keys, rowsplit_vals)}')\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            filename = f\"figs/sensitivity/{dataset_name}-{config_str(rowsplit_keys, rowsplit_vals)} {model_name} sensitivity.pdf\"\n",
    "            #fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            #fig.savefig(filename.replace('pdf', 'png'), dpi=300, bbox_inches='tight')\n",
    "        else:\n",
    "            metric = y_axis.replace('constant_8/', '').replace('/', ' ')\n",
    "            plt.gca().set_title(f'{metric.capitalize()} after {max_epoch_vals[0]} batches')\n",
    "            plt.xlabel('learning rate')\n",
    "\n",
    "            if colorbar:\n",
    "                # Create a color bar with the transformed scale\n",
    "                sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "                sm.set_array([])\n",
    "                cbar = plt.colorbar(sm, ax=plt.gca())\n",
    "                # Set the color bar labels to the original real values\n",
    "                cbar.set_ticks(transformed_momentum_values)\n",
    "                cbar.set_ticklabels([f'{val:.4f}' for val in momentum_values])\n",
    "                cbar.set_label('Momentum')\n",
    "\n",
    "            x_min, x_max = plt.gca().get_xlim()\n",
    "            # Plot a single marker at the rightmost edge\n",
    "            for color, marker, to_plot in hlines:\n",
    "                plt.gca().plot(10**-5, to_plot, marker=marker, color=color, markersize=marker_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_df = read_experiments(['/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-04-convex_clevr_distance',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-04-convex_dmlab',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-04-convex_pendigits',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-04-convex_resisc45',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-04-convex_sun397',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-04-convex_ls_svhn_vit',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-04-imagenet-vit_b32-20-40',\n",
    "\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-15-convex_clevr_distance',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-15-convex_dmlab',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-15-convex_pendigits',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-15-convex_resisc45',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-15-convex_sun397',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-15-convex_ls_svhn_vit',\n",
    "                        '/a/home/cc/students/cs/kreisler/dog/vision_experiments/paper_results/24-04-15-imagenet-vit_b32-0.2-10',\n",
    "\n",
    "                        '/specific/netapp5/joberant/home/maorivgi/code/dog/vision_experiments/paper_results/24-01-22-convex_clevr_distance',\n",
    "                        '/specific/netapp5/joberant/home/maorivgi/code/dog/vision_experiments/paper_results/24-01-22-convex_dmlab',\n",
    "                        '/home/ycarmon/no_backup/users/ycarmon/adog/paper_results/24-01-23-convex_pendigits', \n",
    "                        '/home/ycarmon/no_backup/users/ycarmon/adog/paper_results/24-01-23-convex_pendigits_more_bss',  \n",
    "                        '/specific/netapp5/joberant/home/maorivgi/code/dog/vision_experiments/paper_results/24-01-21-convex_resisc45',\n",
    "                        '/specific/netapp5/joberant/home/maorivgi/code/dog/vision_experiments/paper_results/24-01-21-convex_sun397',\n",
    "                        '/home/ycarmon/no_backup/users/kreisler/accelerated_dog/paper_results/24-03-26-convex_ls_svhn_vit',\n",
    "                        '/home/ycarmon/no_backup/users/ycarmon/adog/paper_results/24-01-24-imagenet-vit_b32'\n",
    "      #'23-10-18-vtab-accelerate-dog-test'\n",
    "                                #'23-09-13-linear_cifar100_resnet50', '23-09-13-linear_cifar100_vit_base_patch32_224_in21k',\n",
    "                                #'23-09-13-linear_clevr_distance_resnet50', '23-09-13-linear_clevr_distance_vit_base_patch32_224_in21k',\n",
    "                                #'23-09-13-linear_dsprites_ori_resnet50', '23-09-13-linear_dsprites_ori_vit_base_patch32_224_in21k',\n",
    "                                #'23-09-13-linear_svhn_resnet50', '23-09-13-linear_svhn_vit_base_patch32_224_in21k'\n",
    "                          ])#, index_field='step')\n",
    "dog_df = dog_df.query('optim_alg == \"dog\" or optim_alg == \"dog_public\" or optim_alg == \"uni_dog\" or optim_alg == \"accele_dog\" or optim_alg == \"unixgrad\" or optim_alg == \"accelegrad\"')\n",
    "dog_df = generate_subopt(dog_df)\n",
    "dog_df = generate_dog_data(dog_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = dog_df.query('dataset == \"wds/imagenet\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['batch_size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.query('batch_size == 32 or batch_size == 512 or batch_size == 8192 or batch_size == 128')\n",
    "# .query('batch_size == 4 or batch_size == 256 or batch_size == 16384')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['batch_size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = filtered_df#.query('batch_size == 4096')\n",
    "make_sensitivity_plots(batch_df, max_epoch_vals=[5, 20, 100], y_lim='auto')  #[100, 400, 1000] #[1000, 10000, 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = filtered_df.copy()#.query('batch_size == 4096')\n",
    "best = np.nanmin(batch_df['train/loss'].apply(np.nanmin))\n",
    "batch_df['train/loss'] -= best\n",
    "make_sensitivity_plots(batch_df, max_epoch_vals=[5, 20, 100], y_lim=[1e-1,10.], y_axis='train/loss') # [1000, 10000, 50000] # [100, 400, 1000] #'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = filtered_df.copy()#.query('batch_size == 4096')\n",
    "best = np.nanmin(batch_df['train/loss'].apply(np.nanmin))\n",
    "batch_df['train/loss'] -= best\n",
    "make_sensitivity_plots(batch_df, max_epoch_vals=[1, 20, 100], y_lim='auto', y_axis='train/rbar') # [1000, 10000, 50000] # [100, 400, 1000] #'auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {'unixgrad': '+', 'accele_dog': '*', 'uni_dog': 's', 'dog_public': 'o', 'accelegrad': 'p'} \n",
    "colors = {'unixgrad': 'blue', 'accele_dog': 'orange', 'uni_dog': 'purple', 'dog_public': 'red', 'accelegrad': 'tab:purple'}\n",
    "colors_bounded = {'unixgrad': {\"True\": 'blue', \"False\": 'cyan'}, 'accelegrad': {\"True\": 'tab:purple', \"False\": 'tab:pink'}}\n",
    "nice_names = {'unixgrad': 'UniXGrad', 'accele_dog': 'A-DoG', 'uni_dog': 'U-DoG', 'dog_public': 'DoG', 'accelegrad': 'AcceleGrad'}\n",
    "names_order = ['accele_dog', 'uni_dog', 'dog_public', 'unixgrad', 'accelegrad']\n",
    "marker_size=7\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cmap = plt.cm.viridis\n",
    "def transform(val):\n",
    "    return -np.log10(1 - val)\n",
    "norm = mcolors.Normalize(vmin=transform(0), vmax=transform(0.9999))\n",
    "\n",
    "def make_sensitivity_plots(big_df_filt, epoch_selection = 'last', max_epoch_vals = [100, 400, 1000, 4000, 10000, 20000], \n",
    "                           rowsplit_keys = ['lr'], x_axis = 'beta1', y_axis = 'test/constant_8/accuracy', baseline_alg_mask = f'optim_alg in (\"adamw\",)',\n",
    "                           baseline_alg_split_keys = ['batch_size'], auto_y_lim_range = 0.05, y_lim = [0.8, 0.95],\n",
    "                           proposed_alg_mask = f'optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], fig=None, axes=None, colorbar=False, legend_ncol=5):\n",
    "    pretty_mode = False\n",
    "    x_axis_categorical = True\n",
    "  \n",
    "    nrows = 1\n",
    "    ncols = len(max_epoch_vals)\n",
    "    assert not ((fig is None) ^ (axes is None))\n",
    "    create_legend = fig is None\n",
    "\n",
    "    direction = 'max'\n",
    "    if 'loss' in y_axis or 'subopt' in y_axis:\n",
    "        direction = 'min'\n",
    "    \n",
    "    for rowsplit_vals, row_df in modified_groupby(big_df_filt,rowsplit_keys):\n",
    "        hlines = []\n",
    "\n",
    "        baseline_alg_df = row_df.query(baseline_alg_mask)\n",
    "        proposed_alg_df = row_df.query(proposed_alg_mask)\n",
    "        \n",
    "        if len(baseline_alg_df) == 0:\n",
    "            continue\n",
    "    \n",
    "        base_size = (7, 7) if not pretty_mode else (4, 4)\n",
    "        if fig is None:\n",
    "            fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(base_size[0] * ncols, base_size[1] * nrows), facecolor='w', sharey='row')\n",
    "        if nrows * ncols == 1:\n",
    "            axes = np.array(axes)\n",
    "        axes = axes.reshape(nrows, ncols)\n",
    "    \n",
    "        for j, max_epoch in enumerate(max_epoch_vals):\n",
    "            plt.sca(axes[0, j])\n",
    "            axes[0, j].clear()\n",
    "            \n",
    "            if len(baseline_alg_df[y_axis].iloc[0].truncate(after=max_epoch)) == 0:\n",
    "                continue\n",
    "                \n",
    "            baselines_to_plot = {}\n",
    "            \n",
    "            for i, (baseline_split_vals, baseline_split_df) in enumerate(baseline_alg_df.groupby(baseline_alg_split_keys, dropna=False)):\n",
    "                if epoch_selection == 'best':\n",
    "                    if direction == 'max':\n",
    "                        baseline_split_df['selected_y'] = baseline_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).max())\n",
    "                    else:\n",
    "                        baseline_split_df['selected_y'] = baseline_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).min())\n",
    "                elif epoch_selection == 'last':\n",
    "                    baseline_split_df['selected_y'] = baseline_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).iloc[-1])\n",
    "                else:\n",
    "                    raise ValueError('?')\n",
    "                if direction == 'max':\n",
    "                    to_plot = baseline_split_df.groupby(x_axis, dropna=False)['selected_y'].max()\n",
    "                else:\n",
    "                    to_plot = baseline_split_df.groupby(x_axis, dropna=False)['selected_y'].min()\n",
    "\n",
    "                if x_axis_categorical:\n",
    "                    # to_plot.index = to_plot.index.fillna('none')\n",
    "                    to_plot.index = pd.Categorical(to_plot.index.values) #, categories=sorted(baseline_alg_df[x_axis].unique()))\n",
    "                # pdb.set_trace()\n",
    "            \n",
    "                baselines_to_plot[config_str(baseline_alg_split_keys, baseline_split_vals)] = to_plot\n",
    "                \n",
    "            baselines_to_plot = pd.DataFrame(baselines_to_plot)\n",
    "            baselines_to_plot.index = baselines_to_plot.index.fillna('none')\n",
    "            # styles = [dict(color=get_color(i), marker=get_marker(i)) for i in range(len(baselines_to_plot))]\n",
    "            # styles = [get_color(i) for i in range(len(baselines_to_plot))]\n",
    "            h = baselines_to_plot.plot(ax=plt.gca(), legend=False, ms=marker_size)\n",
    "            for i, ln in enumerate(h.lines):\n",
    "                ln.set_marker(get_marker(i))\n",
    "                # ln.set_color(get_color(i))\n",
    "                #momentum = float(baselines_to_plot.columns[i].split('momentum = ')[-1])\n",
    "                # pdb.set_trace()\n",
    "                #ln.set_color(get_momentum_color(momentum))\n",
    "                opt_alg = baselines_to_plot.columns[i].split(', ')[0].split('optim_alg = ')[-1]\n",
    "                #ln.set_color(colors_bounded[opt_alg][bounded])\n",
    "    \n",
    "            for ii, (proposed_split_vals, proposed_split_df) in enumerate(proposed_alg_df.groupby(proposed_alg_split_keys, dropna=False)):\n",
    "                if epoch_selection == 'best':\n",
    "                    if direction == 'max':\n",
    "                        proposed_split_df['selected_y'] = proposed_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).max())\n",
    "                    else:\n",
    "                        proposed_split_df['selected_y'] = proposed_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).min())\n",
    "                elif epoch_selection == 'last':\n",
    "                    proposed_split_df['selected_y'] = proposed_split_df[y_axis].apply(lambda x: x.truncate(after=max_epoch).iloc[-1])\n",
    "                else:\n",
    "                    raise ValueError('?')\n",
    "                if direction == 'max':\n",
    "                    to_plot = proposed_split_df['selected_y'].max()\n",
    "                else:\n",
    "                    to_plot = proposed_split_df['selected_y'].min()\n",
    "\n",
    "                # pdb.set_trace()\n",
    "                if len(proposed_split_vals) > 1 or proposed_split_vals[0] not in colors:\n",
    "                    color = colors.get(baseline_split_vals, get_color(-1-ii))\n",
    "                    plt.axhline(to_plot, color=color, ls='--', lw=2, label=f'{config_str(proposed_alg_split_keys, proposed_split_vals)}')\n",
    "                else:\n",
    "                    color = colors[proposed_split_vals[0]]\n",
    "                    marker = markers[proposed_split_vals[0]]\n",
    "                    hlines.append((color, marker, to_plot))\n",
    "                    plt.axhline(to_plot, color=color, lw=2, label=f'{config_str(proposed_alg_split_keys, proposed_split_vals)}')\n",
    "\n",
    "    \n",
    "            plt.title(f'Max {baseline_alg_df[y_axis].iloc[0].index.name} = {max_epoch}')\n",
    "            if not x_axis_categorical:\n",
    "                plt.xscale('log')\n",
    "            if y_lim == 'auto':\n",
    "                # y_max = min(1.0, pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.max()).max() + auto_y_lim_range)\n",
    "                # y_min = min(0.0, pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.min()).min() - auto_y_lim_range)\n",
    "                y_max = min(1.0, np.nanpercentile(pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.max()), 95) + auto_y_lim_range)\n",
    "                y_min = max(0.0, np.nanpercentile(pd.concat([baseline_alg_df, proposed_alg_df], axis=0)[y_axis].apply(lambda x: x.min()), 5) - auto_y_lim_range)\n",
    "                #plt.ylim(y_min, y_max)\n",
    "            else:    \n",
    "                plt.ylim(y_lim)\n",
    "            if 'loss' in y_axis or 'subopt' in y_axis or 'rbar' in y_axis:\n",
    "                plt.yscale('log')\n",
    "            plt.ylabel(y_axis)\n",
    "            plt.xlabel(x_axis)\n",
    "    \n",
    "            plt.grid(True, which='major', axis='y')\n",
    "            if not x_axis_categorical:\n",
    "                plt.grid(True, which='major', axis='x')\n",
    "            plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "    \n",
    "    \n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    \n",
    "        if create_legend:\n",
    "            fig.legend(\n",
    "                    prop={\"size\": 14},\n",
    "            #         columnspacing=0.0,\n",
    "                    ncol=legend_ncol,\n",
    "                    handles=handles,\n",
    "                    labels=labels,\n",
    "                    loc='upper center',\n",
    "                    bbox_to_anchor=[0.5, -0.05],\n",
    "                    frameon=True,\n",
    "                    markerscale=1.0,\n",
    "                )\n",
    "            #dataset_name = big_df_filt.iloc[0].dataset.replace('/', '+')\n",
    "            model_name = big_df_filt.iloc[0].model.replace('/', '+')\n",
    "            \n",
    "            fig.suptitle(f'{config_str(rowsplit_keys, rowsplit_vals)}')\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            #filename = f\"figs/sensitivity/{dataset_name}-{config_str(rowsplit_keys, rowsplit_vals)} {model_name} sensitivity.pdf\"\n",
    "            #fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            #fig.savefig(filename.replace('pdf', 'png'), dpi=300, bbox_inches='tight')\n",
    "        else:\n",
    "            metric = y_axis.replace('constant_8/', '').replace('/', ' ')\n",
    "            plt.gca().set_title(f'{metric.capitalize()} after {max_epoch_vals[0]} batches')\n",
    "            plt.xlabel('learning rate')\n",
    "\n",
    "            if colorbar:\n",
    "                # Create a color bar with the transformed scale\n",
    "                sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "                sm.set_array([])\n",
    "                cbar = plt.colorbar(sm, ax=plt.gca())\n",
    "                # Set the color bar labels to the original real values\n",
    "                cbar.set_ticks(transformed_momentum_values)\n",
    "                cbar.set_ticklabels([f'{val:.4f}' for val in momentum_values])\n",
    "                cbar.set_label('Momentum')\n",
    "\n",
    "            x_min, x_max = plt.gca().get_xlim()\n",
    "            # Plot a single marker at the rightmost edge\n",
    "            for color, marker, to_plot in hlines:\n",
    "                plt.gca().plot(10**-5, to_plot, marker=marker, color=color, markersize=marker_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_big_df = read_experiments(['24-06-01-openwebtext_adam_betas_clipped',\n",
    "                                '24-05-31-openwebtext_adam_betas_clipped_more_bs',\n",
    "                                '24-06-02-openwebtext_adam_betas_clipped_more_lr',\n",
    "                                '24-06-02-openwebtext_adam_betas_clipped_more_lr2'\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/last/loss', epoch_selection='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/last/loss', epoch_selection='last', rowsplit_keys=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/last/loss', epoch_selection='best', rowsplit_keys=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openwebtext_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_df = read_experiments(['24-06-02-openwebtext_dog_clipped',\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_df = generate_dog_data(dog_df, with_effective_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(dog_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg', 'dog_granularity'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(dog_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='last',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg', 'dog_granularity'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_steps = False\n",
    "limit = None #7000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = dog_df#.query('dog_granularity == \"all\"')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['wd']\n",
    "legend_fields = ['optim_alg', 'dog_granularity']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/rbar' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            rbar = entry_df[y_field].iloc[0]\n",
    "            if legend_vals[1] == 'param':\n",
    "                rbar = np.linalg.norm(np.stack(rbar), axis=1)\n",
    "\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            plt.plot(rbar, color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = conv_big_df.query('dog_granularity == \"all\"')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['wd']\n",
    "legend_fields = ['optim_alg']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/rbar' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            plt.plot(sum(entry_df[y_field]) / len(entry_df[y_field]), color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        #plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = conv_big_df.query('dog_granularity == \"param\" and optim_alg != \"dog\"')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['wd']\n",
    "legend_fields = ['optim_alg']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/rbar' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            rbar = entry_df[y_field].iloc[0]\n",
    "            rbar = np.stack(rbar)\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            for l in [0,1] + list(range(10, rbar.shape[1], 20)) + [rbar.shape[1]-2, rbar.shape[1]-1]: #range(rbar.shape[1]):\n",
    "                mu = 1.\n",
    "                if l == 0 or l == rbar.shape[1]-1:\n",
    "                    mu = 224/50432\n",
    "                plt.plot(rbar[:, l]*mu, color=get_color(i_entry*rbar.shape[1] + l), marker=get_marker(i_entry*rbar.shape[1] + l), label=config_str(legend_fields, legend_vals)+\"_\" + str(l))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = conv_big_df.query('dog_granularity == \"param\" and optim_alg == \"dog\"')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['wd']\n",
    "legend_fields = ['optim_alg']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/rbar' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            rbar = entry_df[y_field].iloc[0]\n",
    "            rbar = np.stack(rbar)\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            for l in [0,1] + list(range(10, rbar.shape[1], 20)) + [rbar.shape[1]-2, rbar.shape[1]-1]: #range(rbar.shape[1]):\n",
    "                plt.plot(rbar[:, l], color=get_color(i_entry*rbar.shape[1] + l), marker=get_marker(i_entry*rbar.shape[1] + l), label=config_str(legend_fields, legend_vals)+\"_\" + str(l))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = dog_df#.query('granularity_reverse == True')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['wd']\n",
    "legend_fields = ['optim_alg', 'dog_granularity']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'test/poly_32_1/loss' # 'train/grad_norm' #'test/av/loss'#  'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            plt.plot(entry_df[y_field].iloc[0], color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        plt.ylim([3.8, 6.5])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openwebtext_dadapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_big_df = read_experiments(['24-06-03-openwebtext_dadapt',\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = ['wd'], x_axis = 'batch_size', baseline_alg_mask = f'not optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg', 'lr_scheduler'],\n",
    "                           proposed_alg_mask = f'optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='last',\n",
    "                           rowsplit_keys = ['wd'], x_axis = 'batch_size', baseline_alg_mask = f'not optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg', 'lr_scheduler'],\n",
    "                           proposed_alg_mask = f'optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'not optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg', 'lr_scheduler'],\n",
    "                           proposed_alg_mask = f'optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(conv_big_df, max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='last',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'not optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg', 'lr_scheduler'],\n",
    "                           proposed_alg_mask = f'optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_steps = False\n",
    "limit = None #7000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = conv_big_df.query('wd == 0.0')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['lr_scheduler']\n",
    "legend_fields = ['optim_alg']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/d' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            plt.plot(sum(entry_df[y_field]) / len(entry_df[y_field]), color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        #plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoG granularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_gran_df = read_experiments(['24-06-14-openwebtext_dog_multiple_granularities',\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_gran_df = generate_dog_data(dog_gran_df, with_effective_lr=False, adog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(dog_gran_df.query('granularity_reverse == False'), max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['granularity_attentions', 'granularity_feed_forward'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(dog_gran_df.query('granularity_reverse == True'), max_epoch_vals=[50], y_lim=[3.8, 6.5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['granularity_attentions', 'granularity_feed_forward'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_steps = False\n",
    "limit = None #7000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = dog_gran_df#.query('granularity_reverse == True')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['granularity_reverse']\n",
    "legend_fields = ['granularity_attentions', 'granularity_feed_forward']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/rbar' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            rbar = entry_df[y_field].iloc[0]\n",
    "            rbar = np.linalg.norm(np.stack(rbar), axis=1)\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            plt.plot(rbar, color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = dog_gran_df#.query('granularity_reverse == True')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['granularity_reverse']\n",
    "legend_fields = ['granularity_attentions', 'granularity_feed_forward']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/grad_norm' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            grad_norm = entry_df[y_field].iloc[0]\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            plt.plot(grad_norm, color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = dog_gran_df#.query('granularity_reverse == True')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['granularity_reverse']\n",
    "legend_fields = ['granularity_attentions', 'granularity_feed_forward']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'test/poly_32_1/loss' # 'train/grad_norm' #'test/av/loss'#  'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            plt.plot(entry_df[y_field].iloc[0], color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        plt.ylim([3.8, 6.5])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-DoG granularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adog_gran_df = read_experiments(['24-06-17-openwebtext_a-dog_multiple_granularities',\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adog_gran_df = generate_dog_data(adog_gran_df, with_effective_lr=False, dog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(adog_gran_df.query('granularity_reverse == False'), max_epoch_vals=[50], y_lim=[3.8, 5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['granularity_attentions', 'granularity_feed_forward'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(adog_gran_df.query('granularity_reverse == True'), max_epoch_vals=[50], y_lim=[3.8, 5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['granularity_attentions', 'granularity_feed_forward'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_steps = False\n",
    "limit = None #7000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = adog_gran_df#.query('granularity_reverse == True')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['granularity_reverse']\n",
    "legend_fields = ['granularity_attentions', 'granularity_feed_forward']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'train/rbar' #'test/av/loss'#'test/constant_8/accuracy' #   'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            rbar = entry_df[y_field].iloc[0]\n",
    "            rbar = np.linalg.norm(np.stack(rbar), axis=1)\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            plt.plot(rbar, color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        #plt.ylim([2.00, 3.0])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = adog_gran_df#.query('granularity_reverse == True')\n",
    "\n",
    "row_fields = ['batch_size']\n",
    "col_fields = ['granularity_reverse']\n",
    "legend_fields = ['granularity_attentions', 'granularity_feed_forward']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'test/poly_8_1/loss' # 'train/grad_norm' #'test/av/loss'#  'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            assert (len(entry_df[y_field]) == 1)\n",
    "            # print(rbar.shape) # epoch, layer\n",
    "            plt.plot(entry_df[y_field].iloc[0], color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            pass#plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        plt.ylim([3.8, 6.5])\n",
    "        plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adog_gran_df = read_experiments(['24-06-20-openwebtext_a-dog_momentum_granularity_no_output_embed-norm',\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adog_gran_df = generate_dog_data(adog_gran_df, with_effective_lr=False, dog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plots(adog_gran_df, max_epoch_vals=[50], y_lim=[3.8, 5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['momentum'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoG multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dog_df = read_experiments(['24-06-02-openwebtext_dog_clipped',\n",
    "                            '24-06-14-openwebtext_dog_multiple_granularities',\n",
    "                            '24-06-17-openwebtext_a-dog_multiple_granularities',\n",
    "                            '24-06-01-openwebtext_adam_betas_clipped',\n",
    "                                '24-05-31-openwebtext_adam_betas_clipped_more_bs',\n",
    "                                '24-06-02-openwebtext_adam_betas_clipped_more_lr',\n",
    "                                '24-06-02-openwebtext_adam_betas_clipped_more_lr2'\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dog_df = generate_subopt(a_dog_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a_dog_df.query('(optim_alg==\"dog\" and dog_granularity == \"param\") or (optim_alg==\"adamw\" and beta1==0.9)')\n",
    "make_sensitivity_plots(df, max_epoch_vals=[50], y_lim=[3.8, 5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\") or optim_alg.str.contains(\"adam\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg','granularity_attentions', 'granularity_feed_forward', 'granularity_reverse'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\") and not optim_alg.str.contains(\"adam\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a_dog_df.query('(optim_alg==\"accele_dog\" and dog_granularity == \"param\") or (optim_alg==\"adamw\")')\n",
    "make_sensitivity_plots(df, max_epoch_vals=[50], y_lim=[3.8, 5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\") or optim_alg.str.contains(\"adam\")',\n",
    "                           baseline_alg_split_keys = ['optim_alg','granularity_attentions', 'granularity_feed_forward', 'granularity_reverse'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\") and not optim_alg.str.contains(\"adam\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a_dog_df.query('optim_alg==\"accele_dog\" and dog_granularity == \"param\"')\n",
    "make_sensitivity_plots(df, max_epoch_vals=[50], y_lim=[3.8, 5], y_axis='test/poly_32_1/loss', epoch_selection='best',\n",
    "                           rowsplit_keys = [], x_axis = 'batch_size', baseline_alg_mask = f'optim_alg.str.contains(\"dog\")',\n",
    "                           baseline_alg_split_keys = ['granularity_attentions', 'granularity_feed_forward', 'granularity_reverse'],\n",
    "                           proposed_alg_mask = f'not optim_alg.str.contains(\"dog\")', proposed_alg_split_keys = ['optim_alg'], legend_ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openhermes dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_big_df = read_experiments(['24-05-09-openhermes_dog_6layers_decay_to_init'\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_big_df = generate_subopt(conv_big_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_big_df = select_av(conv_big_df, 'poly_32_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_steps = False\n",
    "limit = None #7000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = conv_big_df.query('dog_granularity == \"param\"')\n",
    "\n",
    "row_fields = ['wd']\n",
    "col_fields = ['batch_size']\n",
    "legend_fields = ['optim_alg']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'test/av/loss'#'test/constant_8/accuracy' #  'train/rbar' # 'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            plt.plot(sum(entry_df[y_field]) / len(entry_df[y_field]), color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        plt.ylim([2.00, 3.0])\n",
    "        #plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_loss_tables(conv_big_df, rows=['optim_alg', 'dog_granularity', 'batch_size'])['layers=6_hidden-dim=224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_loss_tables(conv_big_df, rows=['optim_alg', 'dog_granularity', 'batch_size'])['layers=6_hidden-dim=224']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openhermes adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_adam = read_experiments(['24-05-08-openhermes_adam_betas'\n",
    "                          ], index_field='epoch', folder='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_adam = generate_subopt(conv_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_adam = select_av(conv_adam, 'poly_32_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_steps = False\n",
    "limit = None #7000 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_to_show = ['vtab/clevr_distance', 'vtab/svhn']\n",
    "big_df_filt = conv_adam.query('batch_size == 4')\n",
    "\n",
    "row_fields = ['lr']\n",
    "col_fields = ['wd']\n",
    "legend_fields = ['beta1']\n",
    "specific_fields = {}#{'optim_alg': 'dog', 'loss':'log'}\n",
    "y_field = 'test/last/loss'#'test/constant_8/accuracy' #  'train/rbar' # 'test/last/empirical_subopt' # 'test/last/accuracy' # 'train/empirical_subopt' # 'train/rbar' # 'train/alpha'#'train/eta' # \n",
    "\n",
    "big_df_filt = big_df_filt.sort_values(row_fields + col_fields + legend_fields)\n",
    "n_rows = big_df_filt[row_fields].value_counts().shape[0]\n",
    "n_cols = big_df_filt[col_fields].value_counts().shape[0]\n",
    "\n",
    "print (n_rows, n_cols)\n",
    "\n",
    "base_size = (6,4)\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(base_size[0] * n_cols, base_size[1] * n_rows), facecolor='w')\n",
    "if n_rows * n_cols == 1:\n",
    "    axes = np.array(axes)\n",
    "axes = axes.reshape(n_rows, n_cols)\n",
    "\n",
    "for i_row, (row_vals, row_df) in enumerate(modified_groupby(big_df_filt,row_fields)):\n",
    "    for i_col, (col_vals, row_col_df) in enumerate(modified_groupby(row_df,col_fields)):\n",
    "        plt.sca(axes[i_row, i_col])\n",
    "        for i_entry, (legend_vals, entry_df) in enumerate(modified_groupby(row_col_df,legend_fields)):\n",
    "            skip = False\n",
    "            for field in specific_fields:\n",
    "                idx = legend_fields.index(field)\n",
    "                skip = skip or not (legend_vals[idx]== specific_fields[field])\n",
    "            if skip:\n",
    "                continue\n",
    "            # we average over repeated entries with the same legend key; a better thing would be to add error bars / shaded region\n",
    "            plt.plot(sum(entry_df[y_field]) / len(entry_df[y_field]), color=get_color(i_entry), marker=get_marker(i_entry), label=config_str(legend_fields, legend_vals))\n",
    "        if i_col == 0:\n",
    "            plt.ylabel(config_str(row_fields, row_vals, sep='\\n'))\n",
    "        if i_col == n_cols - 1:  # assuming elements in the plot are the same for every row\n",
    "            plt.legend(loc='upper left', bbox_to_anchor=[1.01, 1.025])\n",
    "        if i_row == n_rows - 1:\n",
    "            plt.xlabel(entry_df.iloc[0][y_field].index.name)\n",
    "        if 'subopt' in y_field:\n",
    "            plt.yscale('log')\n",
    "            plt.ylim([0.00, 1.0])\n",
    "        if 'accuracy' in y_field:\n",
    "            \n",
    "            #plt.ylim([0.5, 0.8])\n",
    "            pass\n",
    "\n",
    "        plt.ylim([2.40, 3.0])\n",
    "        #plt.yscale('log')\n",
    "\n",
    "        xlim = plt.xlim()\n",
    "        if (not (limit is None)) and xlim[1] > limit:\n",
    "            plt.xlim([-1, limit])\n",
    "            xlim = plt.xlim()\n",
    "        \n",
    "        plt.grid(True, which='major', axis='y')\n",
    "        plt.grid(True, which='major', axis='x')\n",
    "        plt.grid(True, which='minor', axis='y', color=[0.9, 0.9, 0.9], linestyle='--')\n",
    "        plt.title(config_str(col_fields, col_vals))\n",
    "\n",
    "fig.suptitle(y_field)\n",
    "#plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_loss_tables(conv_adam.query('batch_size == 4'), rows=['lr', 'beta1'])['layers=6_hidden-dim=224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_loss_tables(conv_adam, rows=['lr', 'beta1', 'batch_size'])['layers=6_hidden-dim=224']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
